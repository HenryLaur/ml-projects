{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "import torch\nfrom torch import nn",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "execution": {
                    "iopub.status.busy": "2023-07-19T18:25:42.337560Z",
                    "iopub.execute_input": "2023-07-19T18:25:42.337945Z",
                    "iopub.status.idle": "2023-07-19T18:25:45.550627Z",
                    "shell.execute_reply.started": "2023-07-19T18:25:42.337912Z",
                    "shell.execute_reply": "2023-07-19T18:25:45.549645Z"
                },
                "trusted": true
            },
            "execution_count": 1,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "from torchvision.utils import save_image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nTRAIN_DIR = \"/kaggle/input/carvana-image-masking-png/train_images/\"\nTRAIN_DIR_MASK = \"/kaggle/input/carvana-image-masking-png/train_masks/\"\nBATCH_SIZE = 4\nLEARNING_RATE = 3e-4\nNUM_WORKERS = 2\nNUM_EPOCHS = 200\nLOAD_MODEL = False\nSAVE_MODEL = True\nCHECKPOINT_UNET = \"unet.pth.tar\"\n\nboth_transform = A.Compose(\n    [A.Resize(width=256, height=256),], additional_targets={\"image0\": \"image\"},\n)\n\ntransform_only_input = A.Compose(\n    [\n        A.HorizontalFlip(p=0.5),\n        A.ColorJitter(p=0.2),\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n        ToTensorV2(),\n    ]\n)\n\ntransform_only_mask = A.Compose(\n    [\n        ToTensorV2(),\n    ]\n)",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T14:46:23.592809Z",
                    "iopub.execute_input": "2023-07-19T14:46:23.593514Z",
                    "iopub.status.idle": "2023-07-19T14:46:25.464521Z",
                    "shell.execute_reply.started": "2023-07-19T14:46:23.593471Z",
                    "shell.execute_reply": "2023-07-19T14:46:25.463504Z"
                },
                "trusted": true
            },
            "execution_count": 2,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
                    "output_type": "stream"
                }
            ]
        },
        {
            "cell_type": "code",
            "source": "from PIL import Image\nimport os\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass CityDataset(Dataset):\n    def __init__(self, root_dir, mask_dir):\n        self.root_dir = root_dir\n        self.mask_dir = mask_dir\n        self.list_file = os.listdir(self.root_dir)\n\n        \n    def __len__(self):\n        return len(self.list_file)\n    \n\n    def __getitem__(self, index):\n        img_file = self.list_file[index]\n        img_path = os.path.join(self.root_dir, img_file)\n        mask_path = os.path.join(self.mask_dir, img_file)\n        input_img = np.array(Image.open(img_path))\n        target_img = np.array(Image.open(mask_path[:-3] + \"png\"))\n        \n        augmentations = both_transform(image=input_img, image0=target_img)\n        input_img, target_img = augmentations['image'], augmentations['image0']\n        \n        input_img = transform_only_input(image=input_img)['image']\n        target_img = transform_only_mask(image=target_img)['image']\n        \n        return input_img, target_img",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T14:46:25.466187Z",
                    "iopub.execute_input": "2023-07-19T14:46:25.466550Z",
                    "iopub.status.idle": "2023-07-19T14:46:25.477139Z",
                    "shell.execute_reply.started": "2023-07-19T14:46:25.466506Z",
                    "shell.execute_reply": "2023-07-19T14:46:25.475407Z"
                },
                "trusted": true
            },
            "execution_count": 3,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "from torch.utils.data import DataLoader\nte_dataset = CityDataset(root_dir=TRAIN_DIR, mask_dir=TRAIN_DIR_MASK)\nte_loader = DataLoader(te_dataset, batch_size=1, shuffle=True, num_workers=1)\n\nbatch= iter(te_loader)\nimages, labels = next(batch)\nimport torchvision.transforms as T\nlabels[0].shape\nprint(torch.unique(labels[0].float() * 255, return_counts=True))\ntransform = T.ToPILImage()\ntransform(labels[0].float())",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T14:46:25.480565Z",
                    "iopub.execute_input": "2023-07-19T14:46:25.480850Z",
                    "iopub.status.idle": "2023-07-19T14:46:26.044009Z",
                    "shell.execute_reply.started": "2023-07-19T14:46:25.480826Z",
                    "shell.execute_reply": "2023-07-19T14:46:26.042780Z"
                },
                "trusted": true
            },
            "execution_count": 4,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "(tensor([  0., 255.]), tensor([53444, 12092]))\n",
                    "output_type": "stream"
                },
                {
                    "execution_count": 4,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "<PIL.Image.Image image mode=L size=256x256>",
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAC+ElEQVR4nO3c23LbMAyEYarT939l96KZpI2lEUUusCDzf1eZxCOAa4qxdWoNAAAAAAAAAAAAAAAAAAAAAAAAAADg1svdAGDGPoCfjn0A9R2RG+/ZBUIbsNUf2PldQejrzqx8hhTEJefX/ewMpPU0//ZyIxBW0/3Xz4xAVkv7oScvAlEl+We+tAQkhUI+8iZF8EuwjZiP/ElfJAQBRHWak8D0RItsM2MvmJ0BoW9TxhyYCzm8w/g5MDUD4t+h+AozAWTM0PAaEwHkrNLRVYZ3srzjfbHrwOgMSDzeGVtqMIDU472hxcYCSD7eHVluKID04/2BBQdWGM/pjqil8Pl2bad7YiJ4vAvsdrrraQC7jf/hvDIPP2IneLTNEm+/OIXuzZUY/F/SCPo2Vmj0rWkT6FoEi41f2k9PANXGL6U4LJ5P+JasGYDQogHopkBPAO6rWM7IElh0BugQgLsBNwJwNzBKtQouG4AKAXS8hu8COyOA+5cU3QNEbTED3A24EcDtK4ouASrMAHcDbrcBbL4HMAMIwN2AGwHc/H33NZAZsG4AotM16wYgQgDuBkapTliuGoDshO2qAcgQgLuBMbpLFhYNQIcA3A24/fgAfrsb6HJ8+1oqvGzrdlP+78MfLb7ef6VQfgacjVV53V7tAP4d6REzFysvgsf/7/Tx9oOkyO0rXIvAWWevqz9oy5wUzZZ3dW7JNaDYk6Syp0DutdnVZkD6lek9BXd5VsKpSjPAcl9CV9H6z/OJrrvB84ImK8cm4Lwnp8Cts95bkh5Uj4nAfUeW+e5x9/Cfd7Dqo0OVLaz59NgrYz2IMlg3gKbJYOkAWpsPYfkA2mQGOwTQWhtOocL4hU08T2GzAD48yGHPAL68PgtchLJ7AF/OAygx/pwTIzWGeq7ymaEUvgCKTIucAIoM9oxtBlTJJCmAt+FWGX/aDCgz4O/SdoGLc/12eWvAcfGzWWorL0NNAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwnz/rD1S3RIbx8AAAAABJRU5ErkJggg==\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "code",
            "source": "import torch\nfrom torchvision.utils import save_image\n\ndef save_some_examples(unet, val_loader, epoch, folder):\n    x, y = next(iter(val_loader))\n    x, y = x.to(DEVICE), y.to(DEVICE)\n    unet.eval()\n    with torch.no_grad():\n        y_fake = unet(x)\n        y_fake = y_fake  # remove normalization#\n        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n        save_image(y.float() , folder + f\"/label_{epoch}.png\")\n    unet.train()\n\n\ndef save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(\"/kaggle/input/models/\" + checkpoint_file, map_location=DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T14:56:12.418754Z",
                    "iopub.execute_input": "2023-07-19T14:56:12.419651Z",
                    "iopub.status.idle": "2023-07-19T14:56:12.431157Z",
                    "shell.execute_reply.started": "2023-07-19T14:56:12.419614Z",
                    "shell.execute_reply": "2023-07-19T14:56:12.430031Z"
                },
                "trusted": true
            },
            "execution_count": 8,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "import torchvision.transforms.functional as TF\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n        \n    def forward(self, x):\n        return self.conv(x)\n    \n    \nclass UNET(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n        super(UNET, self).__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        #Down\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n        \n        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n        \n        for feature in reversed(features):\n            self.ups.append(nn.ConvTranspose2d(2 * feature, feature, 2, 2))\n            self.ups.append(DoubleConv(feature * 2, feature))\n            in_channels = feature\n            \n        self.final = nn.Conv2d(features[0], out_channels, 1)\n        \n    def forward(self, x):\n        skips = []\n        for down in self.downs:\n            x = down(x)\n            skips.append(x)\n            x = self.pool(x)\n        x = self.bottleneck(x)\n        skips = skips[::-1]\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip = skips[idx//2]\n            \n            if skip.shape != x.shape:\n                x = TF.resize(x, size=(skip.shape[2:]))\n            x = self.ups[idx + 1](torch.cat([x, skip], dim=1))\n            \n        return self.final(x)\n    \nx = torch.randn(5, 3, 160, 160)\nunet = UNET()\ny = unet(x)\nprint(y.shape)\nsum(p.numel() for p in unet.parameters() if p.requires_grad)",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T18:25:50.213622Z",
                    "iopub.execute_input": "2023-07-19T18:25:50.214231Z",
                    "iopub.status.idle": "2023-07-19T18:25:54.122658Z",
                    "shell.execute_reply.started": "2023-07-19T18:25:50.214195Z",
                    "shell.execute_reply": "2023-07-19T18:25:54.121747Z"
                },
                "trusted": true
            },
            "execution_count": 2,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "torch.Size([5, 1, 160, 160])\n",
                    "output_type": "stream"
                },
                {
                    "execution_count": 2,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "31037633"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "code",
            "source": "unet",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T18:27:54.804669Z",
                    "iopub.execute_input": "2023-07-19T18:27:54.805418Z",
                    "iopub.status.idle": "2023-07-19T18:27:54.813628Z",
                    "shell.execute_reply.started": "2023-07-19T18:27:54.805380Z",
                    "shell.execute_reply": "2023-07-19T18:27:54.812561Z"
                },
                "trusted": true
            },
            "execution_count": 6,
            "outputs": [
                {
                    "execution_count": 6,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "UNET(\n  (downs): ModuleList(\n    (0): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (1): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (2): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (3): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (ups): ModuleList(\n    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n    (1): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n    (3): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n    (5): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n    (7): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bottleneck): DoubleConv(\n    (conv): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "code",
            "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torchvision.utils import save_image\nprint(SAVE_MODEL)\ntorch.backends.cudnn.benchmark = True\n\ndef train_fn(unet, train_loader, opt, loss_fn, scaler):\n    loop = tqdm(train_loader, leave=True)\n    \n    for idx, (x, y) in enumerate(loop):\n        x, y = x.to(DEVICE), y.float().to(DEVICE)\n        \n        #Train Discriminator\n        with torch.cuda.amp.autocast():\n            segment = unet(x)\n            loss = loss_fn(segment, y)\n        opt.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(opt)\n        scaler.update()\n        loop.set_postfix(loss=loss.item())\n\n        \n        \ndef main():\n    unet = UNET(in_channels=3).to(DEVICE)\n    opt=optim.Adam(unet.parameters(), lr=LEARNING_RATE)\n    \n    loss = nn.BCEWithLogitsLoss()\n    \n    if LOAD_MODEL:\n        load_checkpoint(CHECKPOINT_UNET, unet, opt, LEARNING_RATE)\n        \n    train_dataset = CityDataset(root_dir=TRAIN_DIR, mask_dir=TRAIN_DIR_MASK)\n    train_subset, val_subset = torch.utils.data.random_split(\n        train_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(1))\n    scaler = torch.cuda.amp.GradScaler()\n    \n    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n    \n    for epoch in range(NUM_EPOCHS):\n        train_fn(unet, train_loader, opt, loss, scaler)\n        \n        if(SAVE_MODEL and epoch % 5 == 0):\n            save_checkpoint(unet, opt, filename=CHECKPOINT_UNET)\n        if epoch % 5 == 0:\n            save_some_examples(unet, val_loader, epoch, folder='.')\n\nmain()",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2023-07-19T14:57:07.100268Z",
                    "iopub.execute_input": "2023-07-19T14:57:07.100652Z",
                    "iopub.status.idle": "2023-07-19T16:09:54.555076Z",
                    "shell.execute_reply.started": "2023-07-19T14:57:07.100620Z",
                    "shell.execute_reply": "2023-07-19T16:09:54.553587Z"
                },
                "trusted": true
            },
            "execution_count": 11,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "True\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:24<00:00,  7.05it/s, loss=0.0543]\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "=> Saving checkpoint\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:23<00:00,  7.11it/s, loss=0.177] \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0268]\n100%|██████████| 1018/1018 [02:25<00:00,  6.99it/s, loss=0.0541]\n100%|██████████| 1018/1018 [02:24<00:00,  7.03it/s, loss=0.0445]\n100%|██████████| 1018/1018 [02:23<00:00,  7.09it/s, loss=0.0622]\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "=> Saving checkpoint\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:23<00:00,  7.08it/s, loss=0.0381]\n100%|██████████| 1018/1018 [02:23<00:00,  7.08it/s, loss=0.0269]\n100%|██████████| 1018/1018 [02:22<00:00,  7.16it/s, loss=0.0581] \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0536]\n100%|██████████| 1018/1018 [02:26<00:00,  6.95it/s, loss=0.0477]\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "=> Saving checkpoint\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:24<00:00,  7.07it/s, loss=0.0169] \n100%|██████████| 1018/1018 [02:24<00:00,  7.03it/s, loss=0.0319]\n100%|██████████| 1018/1018 [02:27<00:00,  6.92it/s, loss=0.0642] \n100%|██████████| 1018/1018 [02:23<00:00,  7.09it/s, loss=0.0525]\n100%|██████████| 1018/1018 [02:25<00:00,  7.02it/s, loss=0.0435] \n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "=> Saving checkpoint\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:23<00:00,  7.12it/s, loss=0.0172]\n100%|██████████| 1018/1018 [02:24<00:00,  7.05it/s, loss=0.0135]\n100%|██████████| 1018/1018 [02:23<00:00,  7.07it/s, loss=0.0335] \n100%|██████████| 1018/1018 [02:23<00:00,  7.09it/s, loss=0.0188] \n100%|██████████| 1018/1018 [02:24<00:00,  7.06it/s, loss=0.034]  \n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "=> Saving checkpoint\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0158] \n100%|██████████| 1018/1018 [02:24<00:00,  7.06it/s, loss=0.0249]\n100%|██████████| 1018/1018 [02:21<00:00,  7.20it/s, loss=0.0117] \n100%|██████████| 1018/1018 [02:24<00:00,  7.06it/s, loss=0.0249] \n100%|██████████| 1018/1018 [02:24<00:00,  7.02it/s, loss=0.00599]\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "=> Saving checkpoint\n",
                    "output_type": "stream"
                },
                {
                    "name": "stderr",
                    "text": "100%|██████████| 1018/1018 [02:23<00:00,  7.08it/s, loss=0.0242] \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.032]  \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0208] \n100%|██████████| 1018/1018 [02:24<00:00,  7.05it/s, loss=0.00451]\n 24%|██▍       | 244/1018 [00:35<01:51,  6.97it/s, loss=0.0316] \n",
                    "output_type": "stream"
                }
            ]
        }
    ]
}