{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-19T18:25:42.337560Z","iopub.execute_input":"2023-07-19T18:25:42.337945Z","iopub.status.idle":"2023-07-19T18:25:45.550627Z","shell.execute_reply.started":"2023-07-19T18:25:42.337912Z","shell.execute_reply":"2023-07-19T18:25:45.549645Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import save_image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nTRAIN_DIR = \"/kaggle/input/carvana-image-masking-png/train_images/\"\nTRAIN_DIR_MASK = \"/kaggle/input/carvana-image-masking-png/train_masks/\"\nBATCH_SIZE = 4\nLEARNING_RATE = 3e-4\nNUM_WORKERS = 2\nNUM_EPOCHS = 200\nLOAD_MODEL = False\nSAVE_MODEL = True\nCHECKPOINT_UNET = \"unet.pth.tar\"\n\nboth_transform = A.Compose(\n    [A.Resize(width=256, height=256),], additional_targets={\"image0\": \"image\"},\n)\n\ntransform_only_input = A.Compose(\n    [\n        A.HorizontalFlip(p=0.5),\n        A.ColorJitter(p=0.2),\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n        ToTensorV2(),\n    ]\n)\n\ntransform_only_mask = A.Compose(\n    [\n        ToTensorV2(),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:46:23.592809Z","iopub.execute_input":"2023-07-19T14:46:23.593514Z","iopub.status.idle":"2023-07-19T14:46:25.464521Z","shell.execute_reply.started":"2023-07-19T14:46:23.593471Z","shell.execute_reply":"2023-07-19T14:46:25.463504Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\nimport os\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass CityDataset(Dataset):\n    def __init__(self, root_dir, mask_dir):\n        self.root_dir = root_dir\n        self.mask_dir = mask_dir\n        self.list_file = os.listdir(self.root_dir)\n\n        \n    def __len__(self):\n        return len(self.list_file)\n    \n\n    def __getitem__(self, index):\n        img_file = self.list_file[index]\n        img_path = os.path.join(self.root_dir, img_file)\n        mask_path = os.path.join(self.mask_dir, img_file)\n        input_img = np.array(Image.open(img_path))\n        target_img = np.array(Image.open(mask_path[:-3] + \"png\"))\n        \n        augmentations = both_transform(image=input_img, image0=target_img)\n        input_img, target_img = augmentations['image'], augmentations['image0']\n        \n        input_img = transform_only_input(image=input_img)['image']\n        target_img = transform_only_mask(image=target_img)['image']\n        \n        return input_img, target_img","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:46:25.466187Z","iopub.execute_input":"2023-07-19T14:46:25.466550Z","iopub.status.idle":"2023-07-19T14:46:25.477139Z","shell.execute_reply.started":"2023-07-19T14:46:25.466506Z","shell.execute_reply":"2023-07-19T14:46:25.475407Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nte_dataset = CityDataset(root_dir=TRAIN_DIR, mask_dir=TRAIN_DIR_MASK)\nte_loader = DataLoader(te_dataset, batch_size=1, shuffle=True, num_workers=1)\n\nbatch= iter(te_loader)\nimages, labels = next(batch)\nimport torchvision.transforms as T\nlabels[0].shape\nprint(torch.unique(labels[0].float() * 255, return_counts=True))\ntransform = T.ToPILImage()\ntransform(labels[0].float())","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:46:25.480565Z","iopub.execute_input":"2023-07-19T14:46:25.480850Z","iopub.status.idle":"2023-07-19T14:46:26.044009Z","shell.execute_reply.started":"2023-07-19T14:46:25.480826Z","shell.execute_reply":"2023-07-19T14:46:26.042780Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(tensor([  0., 255.]), tensor([53444, 12092]))\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=L size=256x256>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAC+ElEQVR4nO3c23LbMAyEYarT939l96KZpI2lEUUusCDzf1eZxCOAa4qxdWoNAAAAAAAAAAAAAAAAAAAAAAAAAADg1svdAGDGPoCfjn0A9R2RG+/ZBUIbsNUf2PldQejrzqx8hhTEJefX/ewMpPU0//ZyIxBW0/3Xz4xAVkv7oScvAlEl+We+tAQkhUI+8iZF8EuwjZiP/ElfJAQBRHWak8D0RItsM2MvmJ0BoW9TxhyYCzm8w/g5MDUD4t+h+AozAWTM0PAaEwHkrNLRVYZ3srzjfbHrwOgMSDzeGVtqMIDU472hxcYCSD7eHVluKID04/2BBQdWGM/pjqil8Pl2bad7YiJ4vAvsdrrraQC7jf/hvDIPP2IneLTNEm+/OIXuzZUY/F/SCPo2Vmj0rWkT6FoEi41f2k9PANXGL6U4LJ5P+JasGYDQogHopkBPAO6rWM7IElh0BugQgLsBNwJwNzBKtQouG4AKAXS8hu8COyOA+5cU3QNEbTED3A24EcDtK4ouASrMAHcDbrcBbL4HMAMIwN2AGwHc/H33NZAZsG4AotM16wYgQgDuBkapTliuGoDshO2qAcgQgLuBMbpLFhYNQIcA3A24/fgAfrsb6HJ8+1oqvGzrdlP+78MfLb7ef6VQfgacjVV53V7tAP4d6REzFysvgsf/7/Tx9oOkyO0rXIvAWWevqz9oy5wUzZZ3dW7JNaDYk6Syp0DutdnVZkD6lek9BXd5VsKpSjPAcl9CV9H6z/OJrrvB84ImK8cm4Lwnp8Cts95bkh5Uj4nAfUeW+e5x9/Cfd7Dqo0OVLaz59NgrYz2IMlg3gKbJYOkAWpsPYfkA2mQGOwTQWhtOocL4hU08T2GzAD48yGHPAL68PgtchLJ7AF/OAygx/pwTIzWGeq7ymaEUvgCKTIucAIoM9oxtBlTJJCmAt+FWGX/aDCgz4O/SdoGLc/12eWvAcfGzWWorL0NNAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwnz/rD1S3RIbx8AAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torchvision.utils import save_image\n\ndef save_some_examples(unet, val_loader, epoch, folder):\n    x, y = next(iter(val_loader))\n    x, y = x.to(DEVICE), y.to(DEVICE)\n    unet.eval()\n    with torch.no_grad():\n        y_fake = unet(x)\n        y_fake = y_fake  # remove normalization#\n        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n        save_image(y.float() , folder + f\"/label_{epoch}.png\")\n    unet.train()\n\n\ndef save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(\"/kaggle/input/models/\" + checkpoint_file, map_location=DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:56:12.418754Z","iopub.execute_input":"2023-07-19T14:56:12.419651Z","iopub.status.idle":"2023-07-19T14:56:12.431157Z","shell.execute_reply.started":"2023-07-19T14:56:12.419614Z","shell.execute_reply":"2023-07-19T14:56:12.430031Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n        \n    def forward(self, x):\n        return self.conv(x)\n    \n    \nclass UNET(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n        super(UNET, self).__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        #Down\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n        \n        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n        \n        for feature in reversed(features):\n            self.ups.append(nn.ConvTranspose2d(2 * feature, feature, 2, 2))\n            self.ups.append(DoubleConv(feature * 2, feature))\n            in_channels = feature\n            \n        self.final = nn.Conv2d(features[0], out_channels, 1)\n        \n    def forward(self, x):\n        skips = []\n        for down in self.downs:\n            x = down(x)\n            skips.append(x)\n            x = self.pool(x)\n        x = self.bottleneck(x)\n        skips = skips[::-1]\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip = skips[idx//2]\n            \n            if skip.shape != x.shape:\n                x = TF.resize(x, size=(skip.shape[2:]))\n            x = self.ups[idx + 1](torch.cat([x, skip], dim=1))\n            \n        return self.final(x)\n    \nx = torch.randn(5, 3, 160, 160)\nunet = UNET()\ny = unet(x)\nprint(y.shape)\nsum(p.numel() for p in unet.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T18:25:50.213622Z","iopub.execute_input":"2023-07-19T18:25:50.214231Z","iopub.status.idle":"2023-07-19T18:25:54.122658Z","shell.execute_reply.started":"2023-07-19T18:25:50.214195Z","shell.execute_reply":"2023-07-19T18:25:54.121747Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"torch.Size([5, 1, 160, 160])\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"31037633"},"metadata":{}}]},{"cell_type":"code","source":"unet","metadata":{"execution":{"iopub.status.busy":"2023-07-19T18:27:54.804669Z","iopub.execute_input":"2023-07-19T18:27:54.805418Z","iopub.status.idle":"2023-07-19T18:27:54.813628Z","shell.execute_reply.started":"2023-07-19T18:27:54.805380Z","shell.execute_reply":"2023-07-19T18:27:54.812561Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"UNET(\n  (downs): ModuleList(\n    (0): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (1): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (2): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (3): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (ups): ModuleList(\n    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n    (1): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n    (3): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n    (5): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n    (7): DoubleConv(\n      (conv): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bottleneck): DoubleConv(\n    (conv): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torchvision.utils import save_image\nprint(SAVE_MODEL)\ntorch.backends.cudnn.benchmark = True\n\ndef train_fn(unet, train_loader, opt, loss_fn, scaler):\n    loop = tqdm(train_loader, leave=True)\n    \n    for idx, (x, y) in enumerate(loop):\n        x, y = x.to(DEVICE), y.float().to(DEVICE)\n        \n        #Train Discriminator\n        with torch.cuda.amp.autocast():\n            segment = unet(x)\n            loss = loss_fn(segment, y)\n        opt.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(opt)\n        scaler.update()\n        loop.set_postfix(loss=loss.item())\n\n        \n        \ndef main():\n    unet = UNET(in_channels=3).to(DEVICE)\n    opt=optim.Adam(unet.parameters(), lr=LEARNING_RATE)\n    \n    loss = nn.BCEWithLogitsLoss()\n    \n    if LOAD_MODEL:\n        load_checkpoint(CHECKPOINT_UNET, unet, opt, LEARNING_RATE)\n        \n    train_dataset = CityDataset(root_dir=TRAIN_DIR, mask_dir=TRAIN_DIR_MASK)\n    train_subset, val_subset = torch.utils.data.random_split(\n        train_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(1))\n    scaler = torch.cuda.amp.GradScaler()\n    \n    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n    \n    for epoch in range(NUM_EPOCHS):\n        train_fn(unet, train_loader, opt, loss, scaler)\n        \n        if(SAVE_MODEL and epoch % 5 == 0):\n            save_checkpoint(unet, opt, filename=CHECKPOINT_UNET)\n        if epoch % 5 == 0:\n            save_some_examples(unet, val_loader, epoch, folder='.')\n\nmain()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:57:07.100268Z","iopub.execute_input":"2023-07-19T14:57:07.100652Z","iopub.status.idle":"2023-07-19T16:09:54.555076Z","shell.execute_reply.started":"2023-07-19T14:57:07.100620Z","shell.execute_reply":"2023-07-19T16:09:54.553587Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:24<00:00,  7.05it/s, loss=0.0543]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:23<00:00,  7.11it/s, loss=0.177] \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0268]\n100%|██████████| 1018/1018 [02:25<00:00,  6.99it/s, loss=0.0541]\n100%|██████████| 1018/1018 [02:24<00:00,  7.03it/s, loss=0.0445]\n100%|██████████| 1018/1018 [02:23<00:00,  7.09it/s, loss=0.0622]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:23<00:00,  7.08it/s, loss=0.0381]\n100%|██████████| 1018/1018 [02:23<00:00,  7.08it/s, loss=0.0269]\n100%|██████████| 1018/1018 [02:22<00:00,  7.16it/s, loss=0.0581] \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0536]\n100%|██████████| 1018/1018 [02:26<00:00,  6.95it/s, loss=0.0477]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:24<00:00,  7.07it/s, loss=0.0169] \n100%|██████████| 1018/1018 [02:24<00:00,  7.03it/s, loss=0.0319]\n100%|██████████| 1018/1018 [02:27<00:00,  6.92it/s, loss=0.0642] \n100%|██████████| 1018/1018 [02:23<00:00,  7.09it/s, loss=0.0525]\n100%|██████████| 1018/1018 [02:25<00:00,  7.02it/s, loss=0.0435] \n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:23<00:00,  7.12it/s, loss=0.0172]\n100%|██████████| 1018/1018 [02:24<00:00,  7.05it/s, loss=0.0135]\n100%|██████████| 1018/1018 [02:23<00:00,  7.07it/s, loss=0.0335] \n100%|██████████| 1018/1018 [02:23<00:00,  7.09it/s, loss=0.0188] \n100%|██████████| 1018/1018 [02:24<00:00,  7.06it/s, loss=0.034]  \n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0158] \n100%|██████████| 1018/1018 [02:24<00:00,  7.06it/s, loss=0.0249]\n100%|██████████| 1018/1018 [02:21<00:00,  7.20it/s, loss=0.0117] \n100%|██████████| 1018/1018 [02:24<00:00,  7.06it/s, loss=0.0249] \n100%|██████████| 1018/1018 [02:24<00:00,  7.02it/s, loss=0.00599]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1018/1018 [02:23<00:00,  7.08it/s, loss=0.0242] \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.032]  \n100%|██████████| 1018/1018 [02:23<00:00,  7.10it/s, loss=0.0208] \n100%|██████████| 1018/1018 [02:24<00:00,  7.05it/s, loss=0.00451]\n 24%|██▍       | 244/1018 [00:35<01:51,  6.97it/s, loss=0.0316] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m             save_some_examples(unet, val_loader, epoch, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[11], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_subset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43munet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(SAVE_MODEL \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     49\u001b[0m         save_checkpoint(unet, opt, filename\u001b[38;5;241m=\u001b[39mCHECKPOINT_UNET)\n","Cell \u001b[0;32mIn[11], line 22\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(unet, train_loader, opt, loss_fn, scaler)\u001b[0m\n\u001b[1;32m     20\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 22\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     24\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}