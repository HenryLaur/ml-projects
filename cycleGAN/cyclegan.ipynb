{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-15T09:51:54.263637Z","iopub.execute_input":"2023-07-15T09:51:54.264869Z","iopub.status.idle":"2023-07-15T09:51:57.900765Z","shell.execute_reply.started":"2023-07-15T09:51:54.264822Z","shell.execute_reply":"2023-07-15T09:51:57.899635Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode='reflect'),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.2)\n        )\n        \n    def forward(self, x):\n        return self.conv(x)\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(in_channels, features[0], 4, 2, 1, padding_mode='reflect'),\n            nn.LeakyReLU(0.2)\n        )\n        \n        layers = []\n        in_channels = features[0]\n        \n        for feature in features[1:]:\n            layers.append(Block(in_channels, feature, stride=1 if feature == features[-1] else 2))\n            in_channels = feature\n            \n        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode='reflect'))\n        \n        self.model = nn.Sequential(*layers)\n    def forward(self, x):\n        x = self.initial(x)\n        return torch.sigmoid(self.model(x))\n    \nx = torch.randn((1, 3, 256, 256))\n\nmodel = Discriminator(in_channels=3)\npreds = model(x)\nprint(preds.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:51:57.903513Z","iopub.execute_input":"2023-07-15T09:51:57.904334Z","iopub.status.idle":"2023-07-15T09:51:58.309454Z","shell.execute_reply.started":"2023-07-15T09:51:57.904293Z","shell.execute_reply":"2023-07-15T09:51:58.308238Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"torch.Size([1, 1, 30, 30])\n","output_type":"stream"}]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, padding_mode='reflect', **kwargs)\n            if down\n            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity()\n        )\n        \n    def forward(self, x):\n        return self.conv(x)\n    \nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channels, channels, kernel_size=3, padding=1),\n            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1)\n       )\n    \n    def forward(self, x):\n        return x + self.block(x)\n    \n    \nclass Generator(nn.Module):\n    def __init__(self, in_channels, num_features=64, num_residuals=9):\n        super().__init__()\n        \n        self.initial = nn.Sequential(\n            nn.Conv2d(in_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode='reflect'),\n            nn.ReLU()\n        )\n        \n        self.down_block = nn.ModuleList(\n            [\n                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n            ]\n        )\n        \n        self.residuals = nn.Sequential(\n            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n        )\n        \n        self.up_block = nn.ModuleList(\n            [\n                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n                ConvBlock(num_features*2, num_features, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n            ]\n        )\n        \n        self.final = nn.Conv2d(num_features, in_channels, 7, 1, 3, padding_mode='reflect')\n        \n    def forward(self, x):\n        x = self.initial(x)\n        for layer in self.down_block:\n            x = layer(x)\n            \n        x=self.residuals(x)\n\n        for layer in self.up_block:\n            x = layer(x)\n\n        return torch.tanh(self.final(x))\n\nx = torch.randn((1, 3, 256, 256))\n\nmodel = Generator(in_channels=3)\npreds = model(x)\nprint(preds.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:51:58.314433Z","iopub.execute_input":"2023-07-15T09:51:58.315070Z","iopub.status.idle":"2023-07-15T09:52:00.927698Z","shell.execute_reply.started":"2023-07-15T09:51:58.315029Z","shell.execute_reply":"2023-07-15T09:52:00.926405Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torchvision.utils import save_image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nTRAIN_DIR = \"/kaggle/input/summer2winter-yosemite\"\nVAL_DIR = \"/kaggle/input/summer2winter-yosemite\"\nBATCH_SIZE = 4\nLEARNING_RATE = 1e-5\nLAMBDA_IDENTITY = 0.5\nLAMBDA_CYCLE = 10\nNUM_WORKERS = 2\nNUM_EPOCHS = 200\nLOAD_MODEL = False\nSAVE_MODEL = True\nCHECKPOINT_GEN_S = \"gens.pth.tar\"\nCHECKPOINT_GEN_W = \"genw.pth.tar\"\nCHECKPOINT_DISC_S = \"critics.pth.tar\"\nCHECKPOINT_DISC_W = \"criticw.pth.tar\"\n\ntransformsA = A.Compose(\n    [\n        A.Resize(width=256, height=256),\n        A.HorizontalFlip(p=0.5),\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n        ToTensorV2(),\n    ],\n    additional_targets={\"image0\": \"image\"},\n)\n\nimport random, os\nimport copy\n\ndef save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n\n\ndef seed_everything(seed=42):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:52:00.929720Z","iopub.execute_input":"2023-07-15T09:52:00.930290Z","iopub.status.idle":"2023-07-15T09:52:03.127849Z","shell.execute_reply.started":"2023-07-15T09:52:00.930246Z","shell.execute_reply":"2023-07-15T09:52:03.126640Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\nimport os\nfrom torch.utils.data import Dataset\n\nclass YosemiteDataset(Dataset):\n    def __init__(self, root_summer, root_winter, transform=None):\n        self.root_summer = root_summer\n        self.root_winter = root_winter\n        self.transform = transform\n        \n        self.summer_images = os.listdir(self.root_summer)\n        self.winter_images = os.listdir(self.root_winter)\n        \n        self.length_dataset = max(len(self.summer_images), len(self.winter_images))\n        self.summer_len = len(self.summer_images)\n        self.winter_len = len(self.winter_images)\n        \n    def __len__(self):\n        return self.length_dataset\n    \n    def __getitem__(self, index):\n        summer_img = self.summer_images[index % self.summer_len]\n        winter_img = self.winter_images[index % self.winter_len]\n        \n        summer_path = os.path.join(self.root_summer, summer_img)\n        winter_path = os.path.join(self.root_winter, winter_img)\n        \n        summer_img = np.array(Image.open(summer_path).convert('RGB'))\n        winter_img = np.array(Image.open(winter_path).convert('RGB'))\n    \n        if self.transform:\n            augs = self.transform(image=summer_img, image0=winter_img)\n            summer_img = augs['image']\n            winter_img = augs['image0']\n        \n        return summer_img, winter_img","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:52:03.131259Z","iopub.execute_input":"2023-07-15T09:52:03.131668Z","iopub.status.idle":"2023-07-15T09:52:03.144524Z","shell.execute_reply.started":"2023-07-15T09:52:03.131629Z","shell.execute_reply":"2023-07-15T09:52:03.143389Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nte_dataset = YosemiteDataset(root_summer='/kaggle/input/summer2winter-yosemite/trainA/', root_winter='/kaggle/input/summer2winter-yosemite/trainB/', transform=transformsA)\nte_loader = DataLoader(te_dataset, batch_size=1, shuffle=True, num_workers=1)\n\nbatch= iter(te_loader)\nimage, image0 = next(batch)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:52:03.146930Z","iopub.execute_input":"2023-07-15T09:52:03.147385Z","iopub.status.idle":"2023-07-15T09:52:03.512931Z","shell.execute_reply.started":"2023-07-15T09:52:03.147347Z","shell.execute_reply":"2023-07-15T09:52:03.510641Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!mkdir fake_images\n!mkdir real_images","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:52:03.516609Z","iopub.execute_input":"2023-07-15T09:52:03.517043Z","iopub.status.idle":"2023-07-15T09:52:05.809749Z","shell.execute_reply.started":"2023-07-15T09:52:03.517002Z","shell.execute_reply":"2023-07-15T09:52:05.808235Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nwandb.login(key=UserSecretsClient().get_secret(\"wandb_api\"))\nrun = wandb.init(\n    # Set the project where this run will be logged\n    project=\"my-awesome-project\",\n    # Track hyperparameters and run metadata\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"batch_size\": BATCH_SIZE\n    })","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:52:05.812519Z","iopub.execute_input":"2023-07-15T09:52:05.812981Z","iopub.status.idle":"2023-07-15T09:52:54.669565Z","shell.execute_reply.started":"2023-07-15T09:52:05.812938Z","shell.execute_reply":"2023-07-15T09:52:54.668440Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhenry-laur\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230715_095223-mpin8g84</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/henry-laur/my-awesome-project/runs/mpin8g84' target=\"_blank\">smart-totem-3</a></strong> to <a href='https://wandb.ai/henry-laur/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/henry-laur/my-awesome-project' target=\"_blank\">https://wandb.ai/henry-laur/my-awesome-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/henry-laur/my-awesome-project/runs/mpin8g84' target=\"_blank\">https://wandb.ai/henry-laur/my-awesome-project/runs/mpin8g84</a>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.optim as optim\nfrom torchvision import transforms\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize(1024),\n    #transforms.ToTensor()\n])\n\ndef resize(x):\n    return [transform(x_) for x_ in x]\n\ndef train_fn(disc_S, disc_W, gen_S, gen_W, yosemite_loader, opt_disc, opt_gen, L1, mse, g_scaler, d_scaler, epoch):\n    loop = tqdm(yosemite_loader, leave=True)\n    \n    for idx, (summer, winter) in enumerate(loop):\n        summer = summer.to(DEVICE)\n        winter = winter.to(DEVICE)\n        \n        # Train Disc S, W\n        with torch.cuda.amp.autocast():\n            fake_summer = gen_S(winter)\n            D_S_real = disc_S(summer)\n            D_S_fake = disc_S(fake_summer.detach())\n            D_S_real_loss = mse(D_S_real, torch.ones_like(D_S_real))\n            D_S_fake_loss = mse(D_S_fake, torch.zeros_like(D_S_fake))\n            D_S_loss = D_S_real_loss + D_S_fake_loss\n            \n            \n            fake_winter = gen_W(summer)\n            D_W_real = disc_W(winter)\n            D_W_fake = disc_W(fake_winter.detach())\n            D_W_real_loss = mse(D_W_real, torch.ones_like(D_W_real))\n            D_W_fake_loss = mse(D_W_fake, torch.zeros_like(D_W_fake))\n            D_W_loss = D_W_real_loss + D_W_fake_loss\n    \n            # put it together\n            D_loss = (D_W_loss + D_S_loss) / 2\n            \n        opt_disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n        \n        # Train Gens S, W\n        with torch.cuda.amp.autocast():\n            \n            #Adversarial loss\n            D_S_fake = disc_S(fake_summer)\n            D_W_fake = disc_W(fake_winter)\n            \n            loss_G_S = mse(D_S_fake, torch.ones_like(D_S_fake))\n            loss_G_W = mse(D_W_fake, torch.ones_like(D_W_fake))\n            \n            #Cycle loss\n            cycle_summer = gen_S(fake_winter)\n            cycle_winter = gen_W(fake_summer)\n            cycle_summer_loss = L1(summer, cycle_summer)\n            cycle_winter_loss = L1(winter, cycle_winter)\n            \n            #Identity loss\n            #identity_winter = gen_W(winter)\n            #identity_summer = gen_S(summer)\n            #identity_winter_loss = L1(winter, identity_winter)\n            #identity_summer_loss = L1(summer, identity_summer)\n            \n            # losses\n            G_loss = (\n                loss_G_S + \n                loss_G_W + \n                cycle_summer_loss * LAMBDA_CYCLE + \n                cycle_winter_loss * LAMBDA_CYCLE \n                #identity_summer_loss * LAMBDA_IDENTITY + \n                #identity_winter_loss * LAMBDA_IDENTITY\n            )\n                    \n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n\n        if(idx == len(loop) - 1):      \n            img = [*resize(summer*0.5 + 0.5), *resize(winter*0.5 + 0.5), *resize(fake_winter*0.5 + 0.5), *resize(fake_summer*0.5 + 0.5)]\n            wandb.log({\"examples\": [wandb.Image(image) for image in img]})\n                    \ndef main():\n    disc_S = Discriminator(in_channels=3).to(DEVICE)\n    disc_W = Discriminator(in_channels=3).to(DEVICE)\n    gen_S = Generator(in_channels=3).to(DEVICE)\n    gen_W = Generator(in_channels=3).to(DEVICE)\n    \n    opt_disc = optim.Adam(\n        list(disc_S.parameters()) + list(disc_W.parameters()),\n        lr=LEARNING_RATE,\n        betas=(0.5, 0.999)\n    )\n    opt_gen = optim.Adam(\n        list(gen_S.parameters()) + list(gen_W.parameters()),\n        lr=LEARNING_RATE,\n        betas=(0.5, 0.999)\n    )\n    \n    L1 = nn.L1Loss()\n    mse = nn.MSELoss()\n    \n    if LOAD_MODEL:\n        load_checkpoint(CHECKPOINT_GEN_W, gen_w, opt_gen, LEANING_RATE)\n        load_checkpoint(CHECKPOINT_GEN_S, gen_S, opt_gen, LEANING_RATE)\n        load_checkpoint(CHECKPOINT_DISC_S, disc_S, opt_disc, LEANING_RATE)\n        load_checkpoint(CHECKPOINT_DISC_W, disc_W, opt_disc, LEANING_RATE)\n    \n    yosemite_dataset = YosemiteDataset(root_summer='/kaggle/input/summer2winter-yosemite/trainA/', root_winter='/kaggle/input/summer2winter-yosemite/trainB/', transform=transformsA)\n    yosemite_loader = DataLoader(yosemite_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n\n    g_scaler = torch.cuda.amp.GradScaler()\n    d_scaler = torch.cuda.amp.GradScaler()\n    \n    for epoch in range(NUM_EPOCHS):\n        train_fn(disc_S, disc_W, gen_S, gen_W, yosemite_loader, opt_disc, opt_gen, L1, mse, g_scaler, d_scaler, epoch)\n        \n        if SAVE_MODEL:\n            save_checkpoint(gen_W, opt_gen, filename=CHECKPOINT_GEN_W)\n            save_checkpoint(gen_S, opt_gen, filename=CHECKPOINT_GEN_S)\n            save_checkpoint(disc_S, opt_disc, filename=CHECKPOINT_DISC_W)\n            save_checkpoint(disc_W, opt_disc, filename=CHECKPOINT_DISC_S)\n            wandb.save('/kaggle/working/*pth*')\n    \nmain()","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:54:10.341247Z","iopub.execute_input":"2023-07-15T09:54:10.341640Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 4 files into the W&B run directory, call wandb.save again to sync new files.\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:18<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:18<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:18<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:18<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 308/308 [04:19<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n=> Saving checkpoint\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 100/308 [01:21<02:48,  1.24it/s]","output_type":"stream"}]}]}