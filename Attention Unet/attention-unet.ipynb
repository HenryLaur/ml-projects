{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-19T19:20:23.878537Z","iopub.status.busy":"2023-07-19T19:20:23.878054Z","iopub.status.idle":"2023-07-19T19:20:28.470690Z","shell.execute_reply":"2023-07-19T19:20:28.469676Z","shell.execute_reply.started":"2023-07-19T19:20:23.878492Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T19:20:28.473541Z","iopub.status.busy":"2023-07-19T19:20:28.472923Z","iopub.status.idle":"2023-07-19T19:20:30.509949Z","shell.execute_reply":"2023-07-19T19:20:30.508865Z","shell.execute_reply.started":"2023-07-19T19:20:28.473502Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from torchvision.utils import save_image\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","TRAIN_DIR = \"/kaggle/input/carvana-image-masking-png/train_images/\"\n","TRAIN_DIR_MASK = \"/kaggle/input/carvana-image-masking-png/train_masks/\"\n","BATCH_SIZE = 16\n","LEARNING_RATE = 1e-4\n","NUM_WORKERS = 2\n","NUM_EPOCHS = 200\n","LOAD_MODEL = False\n","SAVE_MODEL = True\n","CHECKPOINT_UNET = \"unetattention.pth.tar\"\n","\n","both_transform = A.Compose(\n","    [A.Resize(width=256, height=256), A.HorizontalFlip(p=0.5)], additional_targets={\"image0\": \"image\"},\n",")\n","\n","transform_only_input = A.Compose(\n","    [\n","        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","transform_only_mask = A.Compose(\n","    [\n","        ToTensorV2(),\n","    ]\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T19:20:30.511920Z","iopub.status.busy":"2023-07-19T19:20:30.511551Z","iopub.status.idle":"2023-07-19T19:20:30.523568Z","shell.execute_reply":"2023-07-19T19:20:30.522472Z","shell.execute_reply.started":"2023-07-19T19:20:30.511885Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import os\n","from torch.utils.data import Dataset\n","import numpy as np\n","\n","class CityDataset(Dataset):\n","    def __init__(self, root_dir, mask_dir):\n","        self.root_dir = root_dir\n","        self.mask_dir = mask_dir\n","        self.list_file = os.listdir(self.root_dir)\n","\n","        \n","    def __len__(self):\n","        return len(self.list_file)\n","    \n","\n","    def __getitem__(self, index):\n","        img_file = self.list_file[index]\n","        img_path = os.path.join(self.root_dir, img_file)\n","        mask_path = os.path.join(self.mask_dir, img_file)\n","        input_img = np.array(Image.open(img_path))\n","        target_img = np.array(Image.open(mask_path[:-3] + \"png\"))\n","        \n","        augmentations = both_transform(image=input_img, image0=target_img)\n","        input_img, target_img = augmentations['image'], augmentations['image0']\n","        \n","        input_img = transform_only_input(image=input_img)['image']\n","        target_img = transform_only_mask(image=target_img)['image']\n","        \n","        return input_img, target_img"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T19:20:30.527687Z","iopub.status.busy":"2023-07-19T19:20:30.527283Z","iopub.status.idle":"2023-07-19T19:20:31.062253Z","shell.execute_reply":"2023-07-19T19:20:31.060931Z","shell.execute_reply.started":"2023-07-19T19:20:30.527634Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([  0., 255.]), tensor([46798, 18738]))\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAADeUlEQVR4nO2d23ajMBAExZ79/1/2PuRiY4QNRjPds6p6iZNDwky5JS7xQa0BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHzcbrdDm0XXcYHlyi//Ntb9K5u2L+0rivNFDXk7fVycqmR4lA08HC0hchhLNRzZec4cJtLwdreJM7hEwZud5h7AFAb+CPa5y9dphZN0zRlMahCsEvDNsdPLQTgKSFXwMm7Sc/ikgfAqAdprmKS9ew6B1lqWgRcCnC9ix2GcgJx3YF+AQQAySnBOQIqBXQEGAWgZVXgnIIE9AR4BSKjDPgG37stx2AuIZkeAywho4aWQgO5PjQIQXUyFBIQaqCAglK4AqxHQYuuplICQe0Q1BARGoCfAbQSEUiMB7RZ2o7g3rmwTEDEJdBJg238IRYbAFxFvTSkBEWwFzDUCSEApAUlHgbnYCHCeAjgKBFBLQEAEngU4j4AWUV6tBAQYqCZguIFyAkYbeBJgPgUEUC8BgykoYGxK1wLmGwEVEzAWBKgLUIMAdQFqEPD4zYRHwZIJGPo+VRQwFASoC1CDAHUBah4FzHgUJAEIUBegBgHqAtQgQF2AGgSoC1CDAHUBHzD0s1IVBQwFAeoC1CDg/nLK2wEk4C5gzgBUTMDYj0z/Cpg0ABUTMBYEqAtQgwB1AUdYdr+5zt+xfy6C2AcL+icg+MGK7gKWpbWVhNE+vIdAwmM1rROwbF8NV2IsYHlsdll9GbmXnxd21wJJT5V1nQPSni7tKSDx4dqOAmZ/tnjuQ/btEpC9xoCZgPwlFqwEKFaYuO9TfiKgWWXFZxIUrTLjMgRkaw15CBAuteQgQLrS1H0OkJWhXXBMngD1emtiAer2V4dBQTH6/lfnAenlGPS/PhFaHCpK5ulMcD4D245NVrnKYnstYFFWHp2Loblmgu7V4EwGdntNmAosPO/eD5hlILy4ITKHgndNBo4ED78HqohyUEZAC3JQSUCLcFBMQGuDJXj0f76M4xKW11ubCDh9R+hNW/eNivBxqXsSlkNb+Ti6WMeqwVPLdbgIGHRT9HQ7Lv2PEWDTzQdc/Ofo8+c4+xs4E19gdxbw8aL597hP/wkCjJrtkZCArQEnJ4oh4NR/UjFvz5d05CSg87lvF9LK+QmBWf8AAAAAAAAAAAAAAAAAAAAAAP87/wCgt1kuGoJZ2gAAAABJRU5ErkJggg==","text/plain":["<PIL.Image.Image image mode=L size=256x256>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from torch.utils.data import DataLoader\n","te_dataset = CityDataset(root_dir=TRAIN_DIR, mask_dir=TRAIN_DIR_MASK)\n","te_loader = DataLoader(te_dataset, batch_size=1, shuffle=True, num_workers=1)\n","\n","batch= iter(te_loader)\n","images, labels = next(batch)\n","import torchvision.transforms as T\n","labels[0].shape\n","print(torch.unique(labels[0].float() * 255, return_counts=True))\n","transform = T.ToPILImage()\n","transform(labels[0].float())"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T19:20:31.071186Z","iopub.status.busy":"2023-07-19T19:20:31.068205Z","iopub.status.idle":"2023-07-19T19:20:31.090060Z","shell.execute_reply":"2023-07-19T19:20:31.089018Z","shell.execute_reply.started":"2023-07-19T19:20:31.071134Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision.utils import save_image\n","\n","def save_some_examples(unet, val_loader, epoch, folder):\n","    x, y = next(iter(val_loader))\n","    x, y = x.to(DEVICE), y.to(DEVICE)\n","    unet.eval()\n","    with torch.no_grad():\n","        y_fake = unet(x)\n","        y_fake[y_fake > 0.5] = 1  # remove normalization#\n","        y_fake[y_fake <= 0.5] = 0  # remove normalization#\n","        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n","        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n","        save_image(y.float() , folder + f\"/label_{epoch}.png\")\n","    unet.train()\n","\n","\n","def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(\"/kaggle/working/\" + checkpoint_file, map_location=DEVICE)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T19:23:56.473034Z","iopub.status.busy":"2023-07-19T19:23:56.472629Z","iopub.status.idle":"2023-07-19T19:23:56.959359Z","shell.execute_reply":"2023-07-19T19:23:56.958183Z","shell.execute_reply.started":"2023-07-19T19:23:56.473003Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 3, 64, 64])\n"]}],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","        \n","    def forward(self, x):\n","        return self.conv(x)\n","    \n","class EncoderBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = ConvBlock(in_channels, out_channels)\n","        self.pool = nn.MaxPool2d(2, 2)\n","    \n","    def forward(self, x):\n","        s = self.conv(x)\n","        p = self.pool(s)\n","        return s, p\n","\n","    \n","class AttentionGate(nn.Module):\n","    def __init__(self, in_channels_input, in_channels_skip, out_channels):\n","        super().__init__()\n","        self.input_conv = nn.Sequential(\n","            nn.Conv2d(in_channels_input, out_channels, kernel_size=1, padding=0, stride=1),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","        \n","        self.skip_conv = nn.Sequential(\n","            nn.Conv2d(in_channels_skip, out_channels, kernel_size=1, padding=0, stride=1),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        \n","        self.output_conv = nn.Sequential(\n","            nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0, stride=1),\n","            nn.Sigmoid()\n","        )\n","        \n","    def forward(self, inputs, skips):\n","        x = self.input_conv(inputs)\n","        s = self.skip_conv(skips)\n","        out = self.relu(x + s)\n","        out = self.output_conv(out)\n","        return out * skips\n","        \n","class DecoderBlock(nn.Module):\n","    def __init__(self, in_channels_input, in_channels_skip, out_channels):\n","        super().__init__()\n","        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        self.attention = AttentionGate(in_channels_input, in_channels_skip, out_channels)\n","        self.c1 = ConvBlock(in_channels_input + out_channels, out_channels)\n","        \n","        \n","    def forward(self, x, skip):\n","\n","        x = self.up(x)\n","        skip = self.attention(x, skip)\n","        x = torch.cat([x, skip], dim=1)\n","        return self.c1(x)\n","        \n","    \n","class AttentionUnet(nn.Module):\n","    def __init__(self, in_channels, out_channels, feature=64):\n","        super().__init__()\n","        self.e1 = EncoderBlock(in_channels, feature)\n","        self.e2 = EncoderBlock(feature, feature * 2)\n","        self.e3 = EncoderBlock(feature * 2, feature * 4)\n","        \n","        self.b1 = ConvBlock(feature * 4, feature * 8)\n","        \n","        self.d1 = DecoderBlock(feature * 8, feature * 4, feature * 4)\n","        self.d2 = DecoderBlock(feature * 4, feature * 2, feature * 2)\n","        self.d3 = DecoderBlock(feature * 2, feature, feature)\n","    \n","        self.final = nn.Conv2d(feature, out_channels, kernel_size=1, padding=0)\n","    \n","    def forward(self, x):\n","        s, p = self.e1(x)\n","        s2, p2 = self.e2(p)\n","        s3, p3 = self.e3(p2)\n","        \n","        b1 = self.b1(p3)\n","        \n","        d1 = self.d1(b1, s3)\n","        d2 = self.d2(d1, s2)\n","        d3 = self.d3(d2, s)\n","        \n","        return self.final(d3)\n","        \n","x = torch.randn((5, 3, 64, 64))\n","model = AttentionUnet(3, 3)\n","print(model(x).shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T19:24:02.683040Z","iopub.status.busy":"2023-07-19T19:24:02.682536Z","iopub.status.idle":"2023-07-19T20:04:10.461331Z","shell.execute_reply":"2023-07-19T20:04:10.458428Z","shell.execute_reply.started":"2023-07-19T19:24:02.683000Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 255/255 [02:56<00:00,  1.44it/s, loss=0.119]\n"]},{"name":"stdout","output_type":"stream","text":["=> Saving checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0778]\n","100%|██████████| 255/255 [02:44<00:00,  1.55it/s, loss=0.0516]\n","100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0361]\n","100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0284]\n","100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0204]\n"]},{"name":"stdout","output_type":"stream","text":["=> Saving checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0172]\n","100%|██████████| 255/255 [02:42<00:00,  1.57it/s, loss=0.0129]\n","100%|██████████| 255/255 [02:42<00:00,  1.57it/s, loss=0.0125]\n","100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0117]\n","100%|██████████| 255/255 [02:42<00:00,  1.57it/s, loss=0.00916]\n"]},{"name":"stdout","output_type":"stream","text":["=> Saving checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 255/255 [02:43<00:00,  1.56it/s, loss=0.0214] \n","100%|██████████| 255/255 [02:42<00:00,  1.57it/s, loss=0.009]  \n","100%|██████████| 255/255 [02:42<00:00,  1.57it/s, loss=0.0079] \n"," 58%|█████▊    | 148/255 [01:35<01:09,  1.55it/s, loss=0.00728]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m             save_some_examples(unet, val_loader, epoch, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[13], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_subset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43munet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(SAVE_MODEL \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     49\u001b[0m         save_checkpoint(unet, opt, filename\u001b[38;5;241m=\u001b[39mCHECKPOINT_UNET)\n","Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(unet, train_loader, opt, loss_fn, scaler)\u001b[0m\n\u001b[1;32m     20\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 22\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     24\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from torchvision.utils import save_image\n","print(SAVE_MODEL)\n","torch.backends.cudnn.benchmark = True\n","\n","def train_fn(unet, train_loader, opt, loss_fn, scaler):\n","    loop = tqdm(train_loader, leave=True)\n","    \n","    for idx, (x, y) in enumerate(loop):\n","        x, y = x.to(DEVICE), y.float().to(DEVICE)\n","        \n","        #Train Discriminator\n","        with torch.cuda.amp.autocast():\n","            segment = unet(x)\n","            loss = loss_fn(segment, y)\n","        opt.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(opt)\n","        scaler.update()\n","        loop.set_postfix(loss=loss.item())\n","\n","        \n","        \n","def main():\n","    unet = AttentionUnet(in_channels=3, out_channels=1).to(DEVICE)\n","    opt=optim.Adam(unet.parameters(), lr=LEARNING_RATE)\n","    \n","    loss = nn.BCEWithLogitsLoss()\n","    \n","    if LOAD_MODEL:\n","        load_checkpoint(CHECKPOINT_UNET, unet, opt, LEARNING_RATE)\n","        \n","    train_dataset = CityDataset(root_dir=TRAIN_DIR, mask_dir=TRAIN_DIR_MASK)\n","    train_subset, val_subset = torch.utils.data.random_split(\n","        train_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(1))\n","    scaler = torch.cuda.amp.GradScaler()\n","    \n","    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n","    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n","    \n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(unet, train_loader, opt, loss, scaler)\n","        \n","        if(SAVE_MODEL and epoch % 5 == 0):\n","            save_checkpoint(unet, opt, filename=CHECKPOINT_UNET)\n","        if epoch % 5 == 0:\n","            save_some_examples(unet, val_loader, epoch, folder='.')\n","\n","main()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
