{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-18T16:23:33.232893Z","iopub.execute_input":"2023-07-18T16:23:33.233309Z","iopub.status.idle":"2023-07-18T16:23:36.437330Z","shell.execute_reply.started":"2023-07-18T16:23:33.233273Z","shell.execute_reply":"2023-07-18T16:23:36.435912Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n# imput img -> hidden dim -> mean, std -> parametrization trick -> decoder -> output img\nclass VariantionalAutoEncoder(nn.Module):\n    def __init__(self, input_dim, h_dim=200, z_dim=20):\n        super().__init__()\n        #encoder\n        self.img_2_hid = nn.Linear(input_dim, h_dim)\n        self.hid_2_mu = nn.Linear(h_dim, z_dim)\n        self.hid_2_sigma = nn.Linear(h_dim, z_dim)\n        \n        #decoder\n        self.z_2_hid = nn.Linear(z_dim, h_dim)\n        self.hid_2_img = nn.Linear(h_dim, input_dim)\n        \n        self.relu = nn.ReLU()\n        \n    def encode(self, x):\n        #q_phy(z|x)\n        h = self.relu(self.img_2_hid(x))\n        \n        mu = self.hid_2_mu(h)\n        sigma = self.hid_2_sigma(h)\n        return mu, sigma\n    \n    def decode(self, z):\n        # p_theta(x|z)\n        h = self.z_2_hid(z)\n        return torch.sigmoid(self.hid_2_img(h))\n    \n    def forward(self, x):\n        mu, sigma = self.encode(x)\n        epsilon = torch.randn_like(sigma)\n        z_reparametrized = mu + sigma * epsilon\n        x_reconstructed = self.decode(z_reparametrized)\n        return x_reconstructed, mu, sigma\n    \nx = torch.randn(4, 784) # 28x28 -> 784\nvae = VariantionalAutoEncoder(input_dim=784)\nprint(\n    vae(x)[0].shape,\n    vae(x)[1].shape,\n    vae(x)[2].shape\n)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-18T16:24:16.526335Z","iopub.execute_input":"2023-07-18T16:24:16.526722Z","iopub.status.idle":"2023-07-18T16:24:16.554170Z","shell.execute_reply.started":"2023-07-18T16:24:16.526693Z","shell.execute_reply":"2023-07-18T16:24:16.552970Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"torch.Size([4, 784]) torch.Size([4, 20]) torch.Size([4, 20])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torchvision.datasets as datasets\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torch.utils.data import DataLoader\nfrom torch import optim\n\n# configuration\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\nINPUT_DIM = 784\nZ_DIM = 20\nH_DIM = 200\nNUM_EPOCHS = 10\nBATCH_SIZE = 128\nLR_RATE = 3e-4 # Karpathy constant\n\n# Dataset loading\ndataset = datasets.MNIST(root=\"kaggle/working/\", train=True, transform=transforms.ToTensor(), download=True)\ntrain_loader = DataLoader(dataset=dataset, shuffle=True, batch_size=BATCH_SIZE)\nmodel = VariantionalAutoEncoder(input_dim=INPUT_DIM)\noptimizer = optim.Adam(model.parameters(), lr=LR_RATE)\nloss_fn = nn.BCELoss(reduction=\"sum\")\n\n# Training\nfor epoch in range(NUM_EPOCHS):\n    loop = tqdm(enumerate(train_loader))\n    for i, (x, _) in loop:\n        # forward\n        x = x.to(DEVICE).view(-1, INPUT_DIM)\n        x_reconstructed, mu, sigma = model(x)\n        \n        # Loss\n        reconstruction_loss = loss_fn(x_reconstructed, x)\n        kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n        \n        # Backprop\n        loss = reconstruction_loss + kl_div\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loop.set_postfix(loss=loss.item())\n        \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-18T17:07:31.111017Z","iopub.execute_input":"2023-07-18T17:07:31.111423Z","iopub.status.idle":"2023-07-18T17:09:28.707642Z","shell.execute_reply.started":"2023-07-18T17:07:31.111392Z","shell.execute_reply":"2023-07-18T17:09:28.706449Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"469it [00:11, 39.30it/s, loss=2.03e+4]\n469it [00:11, 40.43it/s, loss=1.74e+4]\n469it [00:11, 39.38it/s, loss=1.62e+4]\n469it [00:11, 40.29it/s, loss=1.54e+4]\n469it [00:11, 40.23it/s, loss=1.49e+4]\n469it [00:11, 39.49it/s, loss=1.41e+4]\n469it [00:11, 40.38it/s, loss=1.38e+4]\n469it [00:11, 40.24it/s, loss=1.49e+4]\n469it [00:11, 39.41it/s, loss=1.43e+4]\n469it [00:11, 40.18it/s, loss=1.4e+4] \n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef inference(digit, num_examples=1):\n    \"\"\"\n    Generates (num_examples) of a particular digit.\n    Specifically we extract an example of each digit,\n    then after we have the mu, sigma representation for\n    each digit we can sample from that.\n\n    After we sample we can run the decoder part of the VAE\n    and generate examples.\n    \"\"\"\n    images = []\n    idx = 0\n    for x, y in dataset:\n        if y == idx:\n            images.append(x)\n            idx += 1\n        if idx == 10:\n            break\n\n    encodings_digit = []\n    for d in range(10):\n        with torch.no_grad():\n            mu, sigma = model.encode(images[d].view(1, 784))\n\n        encodings_digit.append((mu, sigma))\n\n    mu, sigma = encodings_digit[digit]\n    for example in range(num_examples):\n        epsilon = torch.randn_like(sigma)\n        z = mu + sigma * epsilon\n        out = model.decode(z)\n        out = out.view(-1, 1, 28, 28)\n        save_image(out, f\"generated_{digit}_ex{example}.png\")\n\nfor idx in range(10):\n    inference(idx, num_examples=5)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T17:11:04.060195Z","iopub.execute_input":"2023-07-18T17:11:04.060643Z","iopub.status.idle":"2023-07-18T17:11:04.162074Z","shell.execute_reply.started":"2023-07-18T17:11:04.060607Z","shell.execute_reply":"2023-07-18T17:11:04.160693Z"},"trusted":true},"execution_count":22,"outputs":[]}]}